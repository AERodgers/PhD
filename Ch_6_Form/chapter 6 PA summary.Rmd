---
title: 'Chapter 06: Analysis of Form: Metrical and Lexical effects on the Phonology
  and Phonetics of DCE Intonation'
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r}
require(tidyverse)
require(knitr)
require(stringr)
require(speakr)
# Change this as required
options("speakr.praat.path" = "C:/Program Files/Praat/Praat.exe")

```

```{r}
# Function
balancedData <- function(data_set, treatment_col, response_col,
                         gender_filter, num_speakers, num_reps,
                         use_pa_hierarchy = TRUE)
  # Returns an adjusted data matrix of the phonological data.
  #     data_set = target corpus data set
  #     treatment_col = treatment column / independent variable)
  #     response_col = response column / dependent variable (phonology)
  #     gender_filter = "F" for female only, "M" for male only, "" for all
  #     num_speakers = number of speakers in ideal corpus
  #     num_reps = numer of repetitions per speaker in ideal corpus
  {
  
  if (gender_filter == "M"){
      data_set <- data_set %>% filter(gender == "M")}
  else {
    if (gender_filter == "F"){
      data_set <- data_set %>% filter(gender == "F")
      }
    }
  
    treatment_col = enquo(arg = treatment_col)
    response_col = enquo(arg = response_col)
  
    speakers_per_target = data_set %>%                              # Get number of speakers per target.   
    select(speaker, !!treatment_col) %>% 
    group_by(!!treatment_col) %>%
    summarise(speakers = n_distinct(speaker))
  
  pn_foot_reps <- data_set %>%                                      # Get number of reps per speaker per target.
    group_by(speaker, !!treatment_col) %>%           
    summarise(acc_count = n())
  kable(pn_foot_reps)
  pn_foot_summary <- data_set %>%                                   # Get number of PA tokens per speaker per target
    group_by(speaker, !!treatment_col, !!response_col) %>%
    summarise(acc_count = n()) %>%
    spread(!!response_col, acc_count, is.na <- 0)
  
  balanced <- left_join(                
    pn_foot_summary, pn_foot_reps
    )
  
  pa_columns <- colnames(balanced)[3: (length(colnames(balanced)) -1)]
  
  balanced <- balanced %>% 
    mutate(across(pa_columns,  ~  (.x / acc_count * num_reps))) %>%  # Convert tokens to ratios of tokens per speaker per 
    group_by(!!treatment_col) %>%                                    # target.
    select(-speaker, -acc_count)
  
  num_cols <- length(colnames(balanced))
  
  balanced <- balanced %>%  
    gather(!!response_col, mod_count, 2:num_cols)
  
  if (use_pa_hierarchy){ balanced <- balanced %>% 
    mutate(acc_phon = factor(!!response_col, levels = c(              # Arrange PA levels according to hypothesized hierarchy.
      "(*)", "L*", "H*", ">H*", "L*H"
    )))
  }
  
  balanced <- balanced %>%
    group_by(!!treatment_col, !!response_col) %>% 
    summarise(mod_sum = sum(mod_count)) %>%
    spread(!!response_col, mod_sum) %>% 
    left_join(speakers_per_target) %>%                                          # Adjust token count re number of speakers  
    mutate(across(pa_columns,  ~  round(.x / speakers * num_speakers))) %>%     # per target condition.
    select(-speakers)
  
  return(balanced)
}
```

```{r}

# LOAD CORPUS

corpus <- as_tibble(                                                # Read in AH corpus. 
  read.csv("data/a_corpus_audited.csv")) %>%
  select(speaker:stim, tot_syls:acc_phon,                           # Retain reference columns and phonological data.
         ana_syls, cur_foot:acc_phon, 
         init_phon:fin_phon,
         -tot_syls, -tot_feet                                       # Remove unnecessary columns.
    ) %>%
  mutate(acc_phon = str_replace(acc_phon, "!", "")) %>%             # Ignore downstep.
  mutate(acc_phon = factor(acc_phon, levels = c(                    # Arrange PA levels according to hypothesized hierarchy.
    "(*)", "L*", "H*", ">H*", "L*H"
    ))) %>% 
  mutate(speaker = factor(speaker, levels = c(                      # Arrange PA levels according to hypothesized hierarchy.
    "F5", "F6", "F12", "F15", "F16", "F17",
    "M4", "M5", "M8", "M9", "M10"
    )))


# CREATE PN SUBSETS

pn <- filter(corpus, cur_foot == 1)                                 # Extract PN data.

pn_by_speaker <- pn %>%                                             # Get subset of all data for PN analysis
  filter(stim %in% c(                             
  "A0423", "A1422", "A2422", "A3422",
  "A0131", "A0221", "A0321",
  "H0322", "H0433", "H1321", "H1322"
  )) %>% 
  select(speaker, acc_phon)
  
pn_ana <- pn %>%                                                    # Extract PN anacrusis data.
  filter(stim %in% c("A0423", "A1422", "A2422", "A3422")) %>% 
  select(-(cur_foot:wrd_end_syl), -fin_phon)

pn_foot <- pn %>%                                                   # Extract PN foot-size data.
  filter(stim %in% c("A0131", "A0221", "A0321", "A0423")) %>%
  select(-(ana_syls:cur_foot),-wrd_end_syl, -fin_phon)


pn_lex <- pn %>% filter(stim %in% c(                                # Extract PN word-boundary data. 
  "A0321", "H0322", "H0433", "A0423",  "H1321", "H1322"
  ))

pn_downstep <- as_tibble(                                           # Create corpus for analysis of downstep
  read.csv("data/a_corpus_audited.csv")) %>%
  select(speaker:stim, tot_syls:acc_phon,                           # Retain reference columns and phonological data.
         ana_syls, cur_foot:acc_phon, 
         init_phon:fin_phon,
         -tot_syls, -tot_feet                                       # Remove unnecessary columns.
    ) %>%
  unite(                                                            # create an initial contour column
    init_contour,
    init_phon, acc_phon,
    sep = " ", remove = FALSE) %>% 
  mutate(speaker = factor(speaker, levels = c(                      # Arrange PA levels according to hypothesized hierarchy.
    "F5", "F6", "F12", "F15", "F16", "F17",
    "M4", "M5", "M8", "M9", "M10"
    ))) %>% 
  filter(cur_foot == 1)

# CREATE NUCLEAR PA SUBSETS

nuc <- filter(corpus, cur_foot == 2) %>%                            # Extract nuclear PA data.
  select(-init_phon, -ana_syls) %>%
  unite(nuc_contour, acc_phon, fin_phon, sep = " ", remove = FALSE) # Create nuclear contour column.


nuc_by_speaker <- nuc %>%
  filter(stim %in% c(                                               # Get subset of all data for NUC analysis
  "A1111", "A0221", "A0321", "A0423",  "A1211", "A1231", "A1241"
  )) %>% 
  select(speaker, nuc_contour)

nuc_pre <- nuc %>%                                                  # Extract nuclear PN foot-size data.
  filter(stim %in% c("A1111", "A0221", "A0321", "A0423")) %>% 
  mutate(pre_syls = str_sub(stim, 3,3))  %>%                        # Get number of preceding syllables from stim code
  mutate(pre_syls = as.integer(pre_syls))

nuc_foot <- nuc %>%                            
  filter(stim %in% c("A1211", "A0221", "A1231", "A1241"))           # Get dataset for syllables preceding nuclear PA.

rm(corpus, nuc, pn)                                                 # Remove unneeded variables from R Environment.


```


# **1. Summary of Pitch Accent distributions**
The raw data is unbalanced since there is not an equal number of tokens per speaker per condition. In some cases there are no tokens from one speaker, effectively reducing the number of participants for that condition by one. To make the presentation of these data both honest and representative, summaries are provided based on both the raw unbalanced, and adjusted balanced data are presented.

## **__1.1 Raw Data__**
These table summarize the number of PA tokens per condition regardless of any imbalance in the number of utterances per speaker per condition or the number of speakers per condition.

## 1.1.1 Pre-nuclear Pitch Accents
Foot size data presented first followed by anacrusis data, since the anacrusis targets reflect the number of syllables of anacrusis under maximum foot-size conditions.

### PN Foot-size conditions
```{r results = "asis"}
# Calculate the number of tokens of each PN PA as a function of foot size.
# These are the raw, unadjusted values.

pn_foot_summary_raw <- pn_foot %>%
  group_by(acc_phon, foot_syls) %>%
  summarise(accCount = n()) %>%
  spread(acc_phon, accCount, is.na <- 0) %>% 
  write_csv("output/pn_foot_unbalanced.csv")
kable(pn_foot_summary_raw)
```

### PN Anacrusis conditions
```{r}
# Calculate the number of tokens of each PN PA as a function of anacrusis.
# These are the raw, unadjusted values.

pn_ana_summary_raw <- pn_ana %>%
  group_by(acc_phon, ana_syls) %>%
  summarise(accCount = n()) %>%
  spread(acc_phon, accCount, is.na <- 0) %>% 
  write_csv("output/pn_ana_unbalanced.csv")          # Save the results in a csv file
  kable(pn_ana_summary_raw)                          # output the results in a nice table.
```

## 1.1.2 Nuclear Pitch Accents

### NUC Foot size
```{r}
# Calculate the number of tokens of each NUC PA as a function of foot size.
# These are the raw, unadjusted values.

nuc_foot_summary_raw <- nuc_foot %>%
  group_by(nuc_contour, foot_syls) %>%
  summarise(accCount = n()) %>%
  spread(nuc_contour, accCount, is.na <- 0) %>% 
  write_csv("output/nuc_foot_unbalanced.csv")
  kable(nuc_foot_summary_raw)
```

### NUC Preceding syllable count
```{r}
# Calculate the number of tokens of each NUC PA as a function of foot size.
# These are the raw, unadjusted values.

nuc_pre_summary_raw <- nuc_pre %>%
  group_by(nuc_contour, pre_syls) %>%
  summarise(accCount = n()) %>%
  spread(nuc_contour, accCount, is.na <- 0) %>% 
  write_csv("output/nuc_foot_unbalanced.csv")
  kable(nuc_pre_summary_raw)
```

## 1.1.3 Distribution PA and Nuclear Contour by speaker

### PN accents
```{r}
pn_by_speaker %>% 
  group_by(speaker, acc_phon) %>% 
  summarise(accCount = n()) %>% 
  spread(acc_phon, accCount, is.on <- 0) %>% 
  write_csv("output/pn_by_speaker.csv") %>% 
  kable()
```

### Nuclear Contours
```{r}
nuc_by_speaker %>% 
  group_by(speaker, nuc_contour) %>% 
  summarise(nuc_count = n()) %>% 
  spread(nuc_contour, nuc_count, is.on <- 0) %>% 
  write_csv("output/nuc_by_speaker.csv") %>% 
  kable()
```



## **__1.2 Adjusted Data__**
These Tables summarize the number of PA tokens per condition once adjusted to take into account in the number of utterances per speaker per condition and the number of speakers per condition.

This is the distribution of PAs across conditions adjusted for number of speakers per target and number of repetitions per speaker. It is a better representation of the distribution of the PAs per foot-size condition, although it is not the set of actual values.

## 1.1.1 Distribution PA and Nuclear Contour by speaker

### PN accents
```{r}
pn_by_speaker %>% 
  group_by(speaker, acc_phon) %>% 
  summarise(accCount = n()) %>% 
  spread(acc_phon, accCount, is.on <- 0) %>% 
  write_csv("output/pn_by_speaker.csv") %>% 
  kable()
```

### Nuclear Contours
```{r}
nuc_by_speaker %>% 
  group_by(speaker, nuc_contour) %>% 
  summarise(nuc_count = n()) %>% 
  spread(nuc_contour, nuc_count, is.on <- 0) %>% 
  write_csv("output/nuc_by_speaker.csv") %>% 
  kable()
```


## 1.2.2 Pre-nuclear Pitch Accents

### PN Foot Size

```{r}
# Calculate the adjusted number of tokens of each PN PA as a function of foot 
# size (the target variable). This takes into consideration the number of
# utterances per speaker per target variable and the number of speaker per
# target variable.

balancedData(pn_foot, foot_syls, acc_phon, "", 11, 5) %>% 
  write_csv("output/pn_foot_balanced.csv") %>% 
  kable()

```

### PN Anacrusis
```{r}
# Calculate the adjusted number of tokens of each PN PA as a function of
# anacrusis (the target variable). This takes into consideration the number of
# utterances per speaker per target variable and the number of speaker per
# target variable.

balancedData(pn_ana, ana_syls, acc_phon, "", 11, 5) %>% 
  write_csv("output/pn_ana_balanced.csv") %>% 
  kable()


```

## 1.2.3 Nuclear Pitch Accents

### NUC Foot size
```{r}
# Calculate the adjusted number of tokens of each NUC PA as a function of foot 
# size (the target variable). This takes into consideration the number of
# utterances per speaker per target variable and the number of speaker per
# target variable.

balancedData(nuc_foot, foot_syls, nuc_contour, "", 11, 5) %>% 
  write_csv("output/nuc_foot_balanced.csv") %>% 
  kable()


```

### NUC Preceding syllable count
```{r}
# Calculate the adjusted number of tokens of each NUC PA as a function of number
# of syllables preceding the stressed syllable. This takes into consideration 
# the number of utterances per speaker per target variable and the number of
#  speaker per target variable.
balancedData(nuc_pre, pre_syls, nuc_contour, "", 11, 5) %>% 
  write_csv("output/nuc_pre_balanced.csv") %>% 
  kable()
```



## **__1.3 Graphical Summary of Balanced Data__**

## 1.3.1 Pre-nuclear Pitch Accents

### PNs and Foot Size
```{r}
# creat temp file addresses
my_table_m <- paste(getwd(), "/output/pn_foot_adj_M.csv", sep = "")
my_table_f <- paste(getwd(), "/output/pn_foot_adj_F.csv", sep = "")
my_table_g <- paste(getwd(), "/output/pn_foot_adj_all_gender.csv", sep = "")


pivot_longer(
  balancedData(pn_foot, foot_syls, acc_phon, "M", 5, 5),
  c(2:5),
  names_to = "acc_phon"
  ) %>% 
  write_csv(my_table_m)

pivot_longer(
  balancedData(pn_foot, foot_syls, acc_phon, "F", 6, 5),
  c(2:6),
  names_to = "acc_phon"
  ) %>% 
  write_csv(my_table_f)

# run Praat script for generating representative fake balanced data.
# (This was faster than doing it in R for me!)
script <- "../PraatScripts/adjustedSummaryByGender.praat"
my_treatment <- "foot_syls"
my_response <- "acc_phon"
my_count <- "value"

praat_run(
  script, my_treatment, my_response, my_count, my_table_m, my_table_f, my_table_g
  )

all <- read_csv(my_table_g) %>% 
    mutate(acc_phon = factor(acc_phon, levels = c(                               # Arrange PA levels according to hypothesized hierarchy.
    "(*)", "L*", "H*", ">H*", "L*H"
    )))

ggplot(all) +
  geom_bar(mapping = aes(x = foot_syls, fill = acc_phon),
           colour = "black",
            show.legend = FALSE,
    position = position_dodge2(preserve = "single")) + 
    facet_grid(rows = vars(gender), cols = vars(acc_phon)) +
    ggtitle("PNs by gender and foot syls (adjusted for balance)") +
    scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
    labs(x = "foot size and gender",
         y = "tokens (n)"
         ) +
    theme(panel.border = element_rect(fill = NA))


ggplot(all) +
    geom_bar(mapping = aes(x = foot_syls, fill = acc_phon),
             show.legend = FALSE,
             colour = "black",
             position = position_dodge2(preserve = "single")) +
    facet_grid(cols = vars(acc_phon)) +
    theme(panel.border = element_rect(fill = NA)) +
    ggtitle("PNs across foot size conditions (adjusted for balance)") +
    scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
    labs(x = "foot size (syllables)", y = "tokens (n)") +
    theme(panel.border = element_rect(fill = NA))

unlink(c(my_table_m, my_table_f, my_table_g))
```

### PNs and Anacrusis
```{r}
# creat temp file addresses
my_table_m <- paste(getwd(), "/output/pn_ana_adj_M.csv", sep = "")
my_table_f <- paste(getwd(), "/output/pn_ana_adj_F.csv", sep = "")
my_table_g <- paste(getwd(), "/output/pn_ana_adj_all_gender.csv", sep = "")


pivot_longer(
  balancedData(pn_ana, ana_syls, acc_phon, "M", 5, 5),
  c(2:4),
  names_to = "acc_phon"
  ) %>% 
  write_csv(my_table_m)


pivot_longer(
  balancedData(pn_ana, ana_syls, acc_phon, "F", 6, 5),
  c(2:3),
  names_to = "acc_phon"
  ) %>% 
  write_csv(my_table_f)

# run Praat script for generating representative fake balanced data.
# (This was faster than doing it in R for me!)
script <- "../PraatScripts/adjustedSummaryByGender.praat"
my_treatment <- "ana_syls"
my_response <- "acc_phon"
my_count <- "value"

praat_run(
  script, my_treatment, my_response, my_count, my_table_m, my_table_f, my_table_g
  )

all <- read_csv(my_table_g) %>% 
    mutate(acc_phon = factor(acc_phon, levels = c(                               # Arrange PA levels according to hypothesized hierarchy.
    "(*)", "L*", "H*", ">H*", "L*H"
    )))

ggplot(all) +
  geom_bar(mapping = aes(x = ana_syls, fill = acc_phon),
           colour = "black",
            show.legend = FALSE,
    position = position_dodge2(preserve = "single")) + 
    facet_grid(rows = vars(gender), cols = vars(acc_phon)) +
    ggtitle("PNs by gender and anacrusis (adjusted for balance)") +
    scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
    labs(x = "anacrusis and gender",
         y = "tokens (n)"
         ) +
    theme(panel.border = element_rect(fill = NA))


ggplot(all) +
    geom_bar(mapping = aes(x = ana_syls, fill = acc_phon),
             show.legend = FALSE,
             colour = "black",
             position = position_dodge2(preserve = "single")) +
    facet_grid(cols = vars(acc_phon)) +
    theme(panel.border = element_rect(fill = NA)) +
    ggtitle("PNs across anacrusis conditions (adjusted for balance)") +
    scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
    labs(x = "anacrusis (syllables)", y = "tokens (n)") +
    theme(panel.border = element_rect(fill = NA))

unlink(c(my_table_m, my_table_f, my_table_g))
```

## 1.3.2 Nuclear Pitch Contours
### Nuclear Contours and Foot Size
```{r}
# creat temp file addresses
my_table_m <- paste(getwd(), "/output/nuc_foot_adj_M.csv", sep = "")
my_table_f <- paste(getwd(), "/output/nuc_foot_adj_F.csv", sep = "")
my_table_g <- paste(getwd(), "/output/nuc_foot_adj_all_gender.csv", sep = "")


pivot_longer(
  balancedData(nuc_foot, foot_syls, nuc_contour, "M", 5, 5),
  c(2:3),
  names_to = "nuc_contour"
  ) %>% 
  write_csv(my_table_m)

pivot_longer(
  balancedData(nuc_foot, foot_syls, nuc_contour, "F", 6, 5),
  c(2:3),
  names_to = "nuc_contour"
  ) %>% 
  write_csv(my_table_f)

# run Praat script for generating representative fake balanced data.
# (This was faster than doing it in R for me!)
script <- "../PraatScripts/adjustedSummaryByGender.praat"
my_treatment <- "foot_syls"
my_response <- "nuc_contour"
my_count <- "value"

praat_run(
  script, my_treatment, my_response, my_count, my_table_m, my_table_f, my_table_g
  )

all <- read_csv(my_table_g)

ggplot(all) +
  geom_bar(mapping = aes(x = foot_syls, fill = nuc_contour),
           colour = "black",
            show.legend = FALSE,
    position = position_dodge2(preserve = "single")) + 
    facet_grid(rows = vars(gender), cols = vars(nuc_contour)) +
    ggtitle("Nuclear Contours by Gender and Foot Size (adjusted for balance)") +
    scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
    labs(x = "foot size and gender",
         y = "tokens (n)"
         ) +
    theme(panel.border = element_rect(fill = NA))


ggplot(all) +
    geom_bar(mapping = aes(x = foot_syls, fill = nuc_contour),
             show.legend = FALSE,
             colour = "black",
             position = position_dodge2(preserve = "single")) +
    facet_grid(cols = vars(nuc_contour)) +
    theme(panel.border = element_rect(fill = NA)) +
    ggtitle("Nuclear Contours across Foot Size Conditions (adjusted for balance)") +
    scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
    labs(x = "foot size (syllables)", y = "tokens (n)") +
    theme(panel.border = element_rect(fill = NA))

unlink(c(my_table_m, my_table_f, my_table_g))
```

### Nuclear Contours and Preceding Syllables
```{r}
# creat temp file addresses
my_table_m <- paste(getwd(), "/output/nuc_pre_adj_M.csv", sep = "")
my_table_f <- paste(getwd(), "/output/nuc_pre_adj_F.csv", sep = "")
my_table_g <- paste(getwd(), "/output/nuc_pre_adj_all_gender.csv", sep = "")


pivot_longer(
  balancedData(nuc_pre, pre_syls, nuc_contour, "M", 5, 5),
  c(2:2),
  names_to = "nuc_contour"
  ) %>% 
  write_csv(my_table_m)

pivot_longer(
  balancedData(nuc_pre, pre_syls, nuc_contour, "F", 6, 5),
  c(2:3),
  names_to = "nuc_contour"
  ) %>% 
  write_csv(my_table_f)

# run Praat script for generating representative fake balanced data.
# (This was faster than doing it in R for me!)
script <- "../PraatScripts/adjustedSummaryByGender.praat"
my_treatment <- "pre_syls"
my_response <- "nuc_contour"
my_count <- "value"

praat_run(
  script, my_treatment, my_response, my_count, my_table_m, my_table_f, my_table_g
  )

all <- read_csv(my_table_g)

ggplot(all) +
  geom_bar(mapping = aes(x = pre_syls, fill = nuc_contour),
           colour = "black",
            show.legend = FALSE,
    position = position_dodge2(preserve = "single")) + 
    facet_grid(rows = vars(gender), cols = vars(nuc_contour)) +
    ggtitle("Nuclear Contours by Gender and preceding syllables (adjusted for balance)") +
    scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
    labs(x = "foot size and gender",
         y = "tokens (n)"
         ) +
    theme(panel.border = element_rect(fill = NA))


ggplot(all) +
    geom_bar(mapping = aes(x = pre_syls, fill = nuc_contour),
             show.legend = FALSE,
             colour = "black",
             position = position_dodge2(preserve = "single")) +
    facet_grid(cols = vars(nuc_contour)) +
    theme(panel.border = element_rect(fill = NA)) +
    ggtitle("Nuclear Contours across Foot Size Conditions (adjusted for balance)") +
    scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
    labs(x = "foot size (syllables)", y = "tokens (n)") +
    theme(panel.border = element_rect(fill = NA))

unlink(c(my_table_m, my_table_f, my_table_g))
```

# **__1.4 Initial boundary and downstep__**
### foot size
```{r}
# creat temp file addresses
my_table_m <- paste(getwd(), "/output/M.csv", sep = "")
my_table_f <- paste(getwd(), "/output/F.csv", sep = "")
my_table_g <- paste(getwd(), "/output/G.csv", sep = "")

pn_downstep %>% 
  filter(stim %in% c("A0131", "A0221", "A0321", "A0423")) %>%
  balancedData(foot_syls, init_contour, "M", 5, 5, FALSE) %>% 
  pivot_longer(
    c(2:7),
    names_to = "init_contour"
    ) %>% 
  write_csv(my_table_m)


pn_downstep %>% 
  filter(stim %in% c("A0131", "A0221", "A0321", "A0423")) %>%
  balancedData(foot_syls, init_contour, "F", 5, 6, FALSE) %>% 
  pivot_longer(
    c(2:12),
    names_to = "init_contour"
    ) %>% 
  write_csv(my_table_f)

# run Praat script for generating representative fake balanced data.
# (This was faster than doing it in R for me!)
script <- "../PraatScripts/adjustedSummaryByGender.praat"
my_treatment <- "foot_syls"
my_response <- "init_contour"
my_count <- "value"

praat_run(
  script, my_treatment, my_response, my_count, my_table_m, my_table_f, my_table_g
  )

all <- read_csv(my_table_g)

ggplot(all) +
  geom_bar(mapping = aes(x = foot_syls, fill = init_contour),
           colour = "black",
            show.legend = FALSE,
    position = position_dodge2(preserve = "single")) + 
    facet_grid(rows = vars(gender), cols = vars(init_contour)) +
    ggtitle("PNs by gender and foot size (adjusted for balance)") +
    scale_fill_brewer(palette = "Spectral", name = "Initial Contour") +
    labs(x = "footsize  and gender",
         y = "tokens (n)"
         ) +
    theme(panel.border = element_rect(fill = NA))


ggplot(all) +
    geom_bar(mapping = aes(x = foot_syls, fill = init_contour),
             show.legend = FALSE,
             colour = "black",
             position = position_dodge2(preserve = "single")) +
    facet_grid(cols = vars(init_contour)) +
    theme(panel.border = element_rect(fill = NA)) +
    ggtitle("PNs across fiit size conditions (adjusted for balance)") +
    scale_fill_brewer(palette = "Spectral", name = "init_contour") +
    labs(x = "foot size (syllables)", y = "tokens (n)") +
    theme(panel.border = element_rect(fill = NA))

unlink(c(my_table_m, my_table_f, my_table_g))
```

### anacrusis
```{r}
# creat temp file addresses
my_table_m <- paste(getwd(), "/output/pn_ana_adj_M_ds.csv", sep = "")
my_table_f <- paste(getwd(), "/output/pn_ana_adj_F_ds.csv", sep = "")
my_table_g <- paste(getwd(), "/output/pn_ana_adj_all_gender_ds.csv", sep = "")

pn_downstep %>% 
  filter(stim %in% c("A0423", "A1422", "A2422", "A3422")) %>% 
  balancedData(ana_syls, init_contour, "M", 5, 5, FALSE) %>% 
  pivot_longer(
    c(2:7),
    names_to = "init_contour"
    ) %>% 
  write_csv(my_table_m)


pn_downstep %>% 
  filter(stim %in% c("A0423", "A1422", "A2422", "A3422")) %>% 
  balancedData(ana_syls, init_contour, "F", 5, 6, FALSE) %>% 
  pivot_longer(
    c(2:6),
    names_to = "init_contour"
    ) %>% 
  write_csv(my_table_f)

# run Praat script for generating representative fake balanced data.
# (This was faster than doing it in R for me!)
script <- "../PraatScripts/adjustedSummaryByGender.praat"
my_treatment <- "ana_syls"
my_response <- "init_contour"
my_count <- "value"

praat_run(
  script, my_treatment, my_response, my_count, my_table_m, my_table_f, my_table_g
  )

all <- read_csv(my_table_g)

ggplot(all) +
  geom_bar(mapping = aes(x = ana_syls, fill = init_contour),
           colour = "black",
            show.legend = FALSE,
    position = position_dodge2(preserve = "single")) + 
    facet_grid(rows = vars(gender), cols = vars(init_contour)) +
    ggtitle("PNs by gender and anacrusis (adjusted for balance)") +
    scale_fill_brewer(palette = "Spectral", name = "Initial Contour") +
    labs(x = "anacrusis and gender",
         y = "tokens (n)"
         ) +
    theme(panel.border = element_rect(fill = NA))


ggplot(all) +
    geom_bar(mapping = aes(x = ana_syls, fill = init_contour),
             show.legend = FALSE,
             colour = "black",
             position = position_dodge2(preserve = "single")) +
    facet_grid(cols = vars(init_contour)) +
    theme(panel.border = element_rect(fill = NA)) +
    ggtitle("PNs across anacrusis conditions (adjusted for balance)") +
    scale_fill_brewer(palette = "Spectral", name = "init_contour") +
    labs(x = "anacrusis (syllables)", y = "tokens (n)") +
    theme(panel.border = element_rect(fill = NA))

unlink(c(my_table_m, my_table_f, my_table_g))
```


```{r}

# creat temp file addresses
my_table_m <- paste(getwd(), "/M_ds.csv", sep = "")
my_table_f <- paste(getwd(), "/F_ds.csv", sep = "")
my_table_g <- paste(getwd(), "/allds.csv", sep = "")

pn_downstep %>% 
  filter(stim %in% c("A0423", "A1422", "A2422", "A3422")) %>% 
  select(speaker, init_contour) %>%  
  group_by(speaker, init_contour) %>% 
  summarise(accCount = n()) %>%
  spread(init_contour, accCount, is.on <- 0) %>%
  kable()

 
pn_downstep %>% 
filter(stim %in% c("A0423", "A1422", "A2422", "A3422")) %>%
  select(speaker, init_contour) %>%  
  group_by(speaker, init_contour) %>% 
  summarise(accCount = n()) %>%
  spread(init_contour, accCount, is.on <- 0) %>%
  kable()


```


# **1.5 __Individiual Results__**

```{r results = "asis"}
speaker_list <- unique(pn_foot$speaker)                                         # get vector of speakers

for (cur_speaker in speaker_list)                                               # loop through speaker data
{
  cat(c("##", cur_speaker))
  cat(c("\n### Pre-nuclear contours"))
  
  pn_foot %>%                                                                   # isolate current speaker in PN foot data
  filter (speaker == cur_speaker, .preserve = TRUE) %>%                                             
  group_by(foot_syls, acc_phon) %>%
  summarise(accCount = n()) %>%
  spread(acc_phon, accCount, is.na <- 0, drop = FALSE) %>% 
  kable(caption = c(cur_speaker, "PN foot size effects on PA")) %>% 
  print()

  
  pn_ana %>%                                                                   # isolate current speaker in PN anacrusis data
  filter (speaker == cur_speaker, .preserve = TRUE) %>%                                              
  group_by(ana_syls, acc_phon) %>%
  summarise(accCount = n()) %>%
  spread(acc_phon, accCount, is.na <- 0, drop = FALSE) %>% 
  kable(caption = c(cur_speaker, "PN anacrusis effects on PA")) %>% 
  print()
  
  cat(c("\n### Nuclear contours"))
  
  nuc_foot %>%                                                                   # isolate current speaker in NUC foot data
  filter (speaker == cur_speaker, .preserve = TRUE) %>%                                            
  group_by(foot_syls, nuc_contour) %>%
  mutate(nuc_contour = factor(nuc_contour, levels = c(                          # repeated to avoid inconsistency in "drop = FALSE"
    "L*H %", "L*H L%"
    ))) %>% 
  summarise(accCount = n()) %>%
  spread(nuc_contour, accCount, is.na <- 0, drop = FALSE) %>% 
  kable(caption = c(cur_speaker, "NUC foot size effects on PA")) %>% 
  print()
  
  nuc_pre %>%                                                                   # isolate current speaker in preceding syllables NUC data
  filter (speaker == cur_speaker, .preserve = TRUE) %>%                                               
  group_by(pre_syls, nuc_contour) %>%
  mutate(nuc_contour = factor(nuc_contour, levels = c(                          # repeated to avoid inconsistency in "drop = FALSE"
    "L*H %", "L*H L%"
    ))) %>% 
  summarise(accCount = n()) %>%
  spread(nuc_contour, accCount, is.na <- 0, drop = FALSE) %>% 
  kable(caption = c(cur_speaker, "NUC preceding syllable effects on PA")) %>% 
  print()  
}

```


