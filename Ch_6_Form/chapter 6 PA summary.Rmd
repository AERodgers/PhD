---
title: 'Chapter 06: Analysis of Form: Metrical and Lexical effects on the Phonology
  and Phonetics of DCE Intonation'
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE)
```

```{r}
# Load functions and packages
source("../functions/myFunctions.R") 
installMissingPackages(c("tidyverse", "knitr", "speakr"))

# PRAAT DIRECTORY
# Change this as required
options("speakr.praat.path" = "C:/Program Files/Praat/Praat.exe")
```

```{r}
# LOAD CORPUS
# Read in AH corpus.
corpus <- as_tibble(read.csv("data/a_corpus_audited.csv")) %>%
  # Retain reference columns and phonological data.
  select(
    speaker:stim,
    tot_syls:acc_phon,
    ana_syls,
    cur_foot:acc_phon,
    init_phon:fin_phon,
    -tot_feet
  ) %>%
  # Ignore downstep.
  mutate(acc_phon = str_replace(acc_phon, "!", "")) %>%
  # Arrange PA levels according to hypothesized hierarchy.
  mutate(
    acc_phon = factor(acc_phon,levels = c("(*)", "L*", "H*", ">H*", "L*H"))
    ) %>%
  # Arrange PA levels according to hypothesized hierarchy.
  mutate(speaker = factor(
    speaker,
    levels = c(
      "F5",
      "F6",
      "F12",
      "F15",
      "F16",
      "F17",
      "M4",
      "M5",
      "M8",
      "M9",
      "M10"
    )
  ))


# CREATE PN SUBSETS
# Extract PN data.
pn <- filter(corpus, cur_foot == 1)
# Get subset of all data for PN analysis
pn_by_speaker <- pn %>%
  filter(
    stim %in% c(
      "A0423",
      "A1422",
      "A2422",
      "A3422",
      "A0131",
      "A0221",
      "A0321",
      "H0322",
      "H0433",
      "H1321",
      "H1322"
    )
  ) %>%
  select(speaker, acc_phon)

# Extract PN anacrusis data.
pn_ana <- pn %>%
  filter(stim %in% c("A0423", "A1422", "A2422", "A3422")) %>%
  select(-(cur_foot:wrd_end_syl),-fin_phon)

# Extract PN foot-size data.
pn_foot <- pn %>%
  filter(stim %in% c("A0131", "A0221", "A0321", "A0423")) %>%
  select(-(ana_syls:cur_foot), -wrd_end_syl,-fin_phon)

# Extract PN word-boundary data.
pn_lex <- pn %>% filter(stim %in% c(
  "A0321", "H0322", "H0433", "A0423",  "H1321", "H1322"
  ))

# remove word boundary condition only
pn_by_speaker <- pn %>%
  filter(stim %in% c("A0423",
                     "A1422",
                     "A2422",
                     "A3422",
                     "A0131",
                     "A0221",
                     "A0321")) %>%
  select(speaker, acc_phon)

# Create corpus for analysis of downstep
pn_downstep <- as_tibble(read.csv("data/a_corpus_audited.csv")) %>%
  # Retain reference columns and phonological data.
  select(
    speaker:stim,
    tot_syls:acc_phon,
    ana_syls,
    cur_foot:acc_phon,
    init_phon:fin_phon,
    # Remove unnecessary columns.-tot_syls,
    -tot_feet
  ) %>%
  # create an initial contour column
  unite(init_contour,
        init_phon,
        acc_phon,
        sep = " ",
        remove = FALSE) %>%
  # Arrange speaker factors more intuitively.
  mutate(speaker = factor(
    speaker,
    levels = c(
      "F5",
      "F6",
      "F12",
      "F15",
      "F16",
      "F17",
      "M4",
      "M5",
      "M8",
      "M9",
      "M10"
    )
  )) %>%
  filter(cur_foot == 1)

# CREATE NUCLEAR PA SUBSETS

# Extract nuclear PA data.
nuc <- filter(corpus, cur_foot == 2) %>%
  select(-init_phon,-ana_syls) %>%
  # Create nuclear contour column.
  unite(nuc_contour,
        acc_phon,
        fin_phon,
        sep = " ",
        remove = FALSE)


nuc_by_speaker <- nuc %>%
  # Get subset of all data for NUC analysis
  filter(stim %in% c("A1111", "A0221", "A0321", "A0423",  "A1211", "A1231", "A1241")) %>%
  select(speaker, nuc_contour)

# Extract nuclear PN foot-size data.
nuc_pre <- nuc %>%
  filter(stim %in% c("A1111", "A0221", "A0321", "A0423")) %>%
  # Get number of preceding syllables from stim code
  mutate(pre_syls = str_sub(stim, 3, 3))  %>%
  mutate(pre_syls = as.integer(pre_syls) - 1)

nuc_foot <- nuc %>%
  # Get dataset for syllables preceding nuclear PA.
  filter(stim %in% c("A1211", "A0221", "A1231", "A1241"))

# Remove unneeded variables from R Environment.
rm(corpus, nuc, pn)


```


# **1. Summary of Pitch Accent distributions**
The raw data is unbalanced since there is not an equal number of tokens per speaker per condition. In some cases there are no tokens from one speaker, effectively reducing the number of participants for that condition by one. To make the presentation of these data both honest and representative, summaries are provided based on both the raw unbalanced, and adjusted balanced data are presented.

## **__1.1 Raw Data__**
These table summarize the number of PA tokens per condition regardless of any imbalance in the number of utterances per speaker per condition or the number of speakers per condition.

## 1.1.1 Pre-nuclear Pitch Accents
Foot size data presented first followed by anacrusis data, since the anacrusis targets reflect the number of syllables of anacrusis under maximum foot-size conditions.

### PN Foot-size conditions
```{r}
# Calculate the number of tokens of each PN PA as a function of foot size.
# These are the raw, unadjusted values.

pn_foot_summary_raw <- pn_foot %>%
  group_by(acc_phon, foot_syls) %>%
  summarise(accCount = n()) %>%
  spread(acc_phon, accCount, is.na <- 0) %>%
  write_csv("output/pn_foot_unbalanced.csv")
kable(pn_foot_summary_raw)
```

### PN Anacrusis conditions
```{r}
# Calculate the number of tokens of each PN PA as a function of anacrusis.
# These are the raw, unadjusted values.

pn_ana_summary_raw <- pn_ana %>%
  group_by(acc_phon, ana_syls) %>%
  summarise(accCount = n()) %>%
  spread(acc_phon, accCount, is.na <- 0) %>%
  # Save the results in a csv file
  write_csv("output/pn_ana_unbalanced.csv")

# output the results in a nice table.
kable(pn_ana_summary_raw)                             
```

## 1.1.2 Nuclear Pitch Accents

### NUC Foot size
```{r}
# Calculate the number of tokens of each NUC PA as a function of foot size.
# These are the raw, unadjusted values.

nuc_foot_summary_raw <- nuc_foot %>%
  group_by(nuc_contour, foot_syls) %>%
  summarise(accCount = n()) %>%
  spread(nuc_contour, accCount, is.na <- 0) %>%
  write_csv("output/nuc_foot_unbalanced.csv")
kable(nuc_foot_summary_raw)
```

### NUC Preceding syllable count
```{r}
# Calculate the number of tokens of each NUC PA as a function of foot size.
# These are the raw, unadjusted values.

nuc_pre_summary_raw <- nuc_pre %>%
  group_by(nuc_contour, pre_syls) %>%
  summarise(accCount = n()) %>%
  spread(nuc_contour, accCount, is.na <- 0) %>%
  write_csv("output/nuc_foot_unbalanced.csv")
kable(nuc_pre_summary_raw)
```

## 1.1.3 Distribution PA and Nuclear Contour by speaker

### PN accents
```{r}
pn_by_speaker %>%
  group_by(speaker, acc_phon) %>%
  summarise(accCount = n()) %>%
  spread(acc_phon, accCount, is.on <- 0) %>%
  write_csv("output/pn_by_speaker.csv") %>%
  kable()
kable(summary(pn_by_speaker, n=Inf))

```

### Nuclear Contours
```{r}
nuc_by_speaker %>%
  group_by(speaker, nuc_contour) %>%
  summarise(nuc_count = n()) %>%
  spread(nuc_contour, nuc_count, is.on <- 0) %>%
  write_csv("output/nuc_by_speaker.csv") %>%
  kable()
```



## **__1.2 Adjusted Data__**
These Tables summarize the number of PA tokens per condition once adjusted to take into account in the number of utterances per speaker per condition and the number of speakers per condition.

This is the distribution of PAs across conditions adjusted for number of speakers per target and number of repetitions per speaker. It is a better representation of the distribution of the PAs per foot-size condition, although it is not the set of actual values.

## 1.1.1 Distribution PA and Nuclear Contour by speaker

### PN accents
```{r}
pn_by_speaker %>%
  group_by(speaker, acc_phon) %>%
  summarise(accCount = n()) %>%
  spread(acc_phon, accCount, is.on <- 0) %>%
  write_csv("output/pn_by_speaker.csv") %>%
  kable()
```

### Nuclear Contours
```{r}
nuc_by_speaker %>%
  group_by(speaker, nuc_contour) %>%
  summarise(nuc_count = n()) %>%
  spread(nuc_contour, nuc_count, is.on <- 0) %>%
  write_csv("output/nuc_by_speaker.csv") %>%
  kable()
```


## 1.2.2 Pre-nuclear Pitch Accents

### PN Foot Size

```{r}
# Calculate the adjusted number of tokens of each PN PA as a function of foot 
# size (the target variable). This takes into consideration the number of
# utterances per speaker per target variable and the number of speaker per
# target variable.

balancedData(pn_foot, foot_syls, acc_phon, "", 11, 5) %>%
  write_csv("output/pn_foot_balanced.csv") %>%
  kable()

```

### PN Anacrusis
```{r}
# Calculate the adjusted number of tokens of each PN PA as a function of
# anacrusis (the target variable). This takes into consideration the number of
# utterances per speaker per target variable and the number of speaker per
# target variable.

balancedData(pn_ana, ana_syls, acc_phon, "", 11, 5) %>%
  write_csv("output/pn_ana_balanced.csv") %>%
  kable()


```

## 1.2.3 Nuclear Pitch Accents

### NUC Foot size
```{r}
# Calculate the adjusted number of tokens of each NUC PA as a function of foot 
# size (the target variable). This takes into consideration the number of
# utterances per speaker per target variable and the number of speaker per
# target variable.

balancedData(nuc_foot, foot_syls, nuc_contour, "", 11, 5) %>%
  write_csv("output/nuc_foot_balanced.csv") %>%
  kable()


```

### NUC Preceding syllable count
```{r}
# Calculate the adjusted number of tokens of each NUC PA as a function of number
# of syllables preceding the stressed syllable. This takes into consideration
# the number of utterances per speaker per target variable and the number of
#  speaker per target variable.
balancedData(nuc_pre, pre_syls, nuc_contour, "", 11, 5) %>%
  write_csv("output/nuc_pre_balanced.csv") %>%
  kable()
```



## **__1.3 Graphical Summary of Balanced Data__**

## 1.3.1 Pre-nuclear Pitch Accents

### PNs and Foot Size
```{r}
# creat temp file addresses
my_table_m <- paste(getwd(), "/output/pn_foot_adj_M.csv", sep = "")
my_table_f <- paste(getwd(), "/output/pn_foot_adj_F.csv", sep = "")
my_table_g <-
  paste(getwd(), "/output/pn_foot_adj_all_gender.csv", sep = "")


pivot_longer(balancedData(pn_foot, foot_syls, acc_phon, "M", 5, 5),
             c(2:5),
             names_to = "acc_phon") %>%
  write_csv(my_table_m)

pivot_longer(balancedData(pn_foot, foot_syls, acc_phon, "F", 6, 5),
             c(2:6),
             names_to = "acc_phon") %>%
  write_csv(my_table_f)

# run Praat script for generating representative fake balanced data.
# (This was faster than doing it in R for me!)
script <- "../PraatScripts/adjustedSummaryByGender.praat"
my_treatment <- "foot_syls"
my_response <- "acc_phon"
my_count <- "value"

praat_run(script,
          my_treatment,
          my_response,
          my_count,
          my_table_m,
          my_table_f,
          my_table_g)

all <- read_csv(my_table_g) %>%
  # Arrange PA levels according to hypothesized hierarchy.
  mutate(acc_phon = factor(acc_phon, levels = c("(*)", "L*", "H*", ">H*", "L*H")))
```


```{r, fig.height=7, fig.width=12}
ggplot(all) +
  geom_bar(
    mapping = aes(x = foot_syls, fill = acc_phon),
    colour = "black",
    show.legend = FALSE,
    position = position_dodge2(preserve = "single")
  ) +
  facet_grid(rows = vars(gender), cols = vars(acc_phon)) +
  ggtitle("PNs by gender and foot syls (adjusted)") +
  scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
  labs(x = "foot size and gender",
       y = "tokens (n)") +
  theme(panel.border = element_rect(fill = NA))
```

### PNs across foot size conditions (adjusted) 

```{r fig.height=4, fig.width=12}
ggplot(all) +
  geom_bar(
    mapping = aes(x = foot_syls, fill = acc_phon),
    show.legend = FALSE,
    colour = "black",
    position = position_dodge2(preserve = "single")
  ) +
  facet_grid(cols = vars(acc_phon)) +
  theme(
    panel.border = element_rect(fill = NA),
    axis.text = element_text(size = 14),
    axis.title = element_text(size = 16)
    ) +
  #ggtitle("PNs across foot size conditions (adjusted)") +
  scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
  labs(x = "foot size (syllables)", y = "tokens (n)") +
  theme(panel.border = element_rect(fill = NA))
    

unlink(c(my_table_m, my_table_f, my_table_g))
```

### PNs and Anacrusis
```{r}
# create temp file addresses
my_table_m <- paste(getwd(), "/output/pn_ana_adj_M.csv", sep = "")
my_table_f <- paste(getwd(), "/output/pn_ana_adj_F.csv", sep = "")
my_table_g <-
  paste(getwd(), "/output/pn_ana_adj_all_gender.csv", sep = "")


pivot_longer(balancedData(pn_ana, ana_syls, acc_phon, "M", 5, 5),
             c(2:4),
             names_to = "acc_phon") %>%
  write_csv(my_table_m)


pivot_longer(balancedData(pn_ana, ana_syls, acc_phon, "F", 6, 5),
             c(2:3),
             names_to = "acc_phon") %>%
  write_csv(my_table_f)

# run Praat script for generating representative fake balanced data.
# (This was faster than doing it in R for me!)
script <- "../PraatScripts/adjustedSummaryByGender.praat"
my_treatment <- "ana_syls"
my_response <- "acc_phon"
my_count <- "value"

praat_run(script,
          my_treatment,
          my_response,
          my_count,
          my_table_m,
          my_table_f,
          my_table_g)

all <- read_csv(my_table_g) %>%
  # Arrange PA levels according to hypothesized hierarchy.
  mutate(acc_phon = factor(acc_phon, levels = c(
    "(*)", "L*", "H*", ">H*", "L*H")))
```


```{r fig.height=7, fig.width=8}
ggplot(all) +
  geom_bar(
    mapping = aes(x = ana_syls, fill = acc_phon),
    colour = "black",
    show.legend = FALSE,
    position = position_dodge2(preserve = "single")
  ) +
  facet_grid(rows = vars(gender), cols = vars(acc_phon)) +
  ggtitle("PNs by gender and anacrusis (adjusted)") +
  scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
  labs(x = "anacrusis and gender",
       y = "tokens (n)") +
  theme(panel.border = element_rect(fill = NA))
```


```{r fig.height=4, fig.width=8}
ggplot(all) +
  geom_bar(
    mapping = aes(x = ana_syls, fill = acc_phon),
    show.legend = FALSE,
    colour = "black",
    position = position_dodge2(preserve = "single")
  ) +
  facet_grid(cols = vars(acc_phon)) +
    theme(
    panel.border = element_rect(fill = NA),
    axis.text = element_text(size = 14),
    axis.title = element_text(size = 16)
    ) +
  theme(panel.border = element_rect(fill = NA)) +
  #ggtitle("PNs across anacrusis conditions (adjusted)") +
  scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
  labs(x = "anacrusis (syllables)", y = "tokens (n)") +
  theme(panel.border = element_rect(fill = NA))

unlink(c(my_table_m, my_table_f, my_table_g))
```

## 1.3.2 Nuclear Pitch Contours
### Nuclear Contours and Foot Size
```{r}
# create temp file addresses
my_table_m <- paste(getwd(), "/output/nuc_foot_adj_M.csv", sep = "")
my_table_f <- paste(getwd(), "/output/nuc_foot_adj_F.csv", sep = "")
my_table_g <-
  paste(getwd(), "/output/nuc_foot_adj_all_gender.csv", sep = "")


pivot_longer(balancedData(nuc_foot, foot_syls, nuc_contour, "M", 5, 5),
             c(2:3),
             names_to = "nuc_contour") %>%
  write_csv(my_table_m)

pivot_longer(balancedData(nuc_foot, foot_syls, nuc_contour, "F", 6, 5),
             c(2:3),
             names_to = "nuc_contour") %>%
  write_csv(my_table_f)

# run Praat script for generating representative fake balanced data.
# (This was faster than doing it in R for me!)
script <- "../PraatScripts/adjustedSummaryByGender.praat"
my_treatment <- "foot_syls"
my_response <- "nuc_contour"
my_count <- "value"

praat_run(script,
          my_treatment,
          my_response,
          my_count,
          my_table_m,
          my_table_f,
          my_table_g)

all <- read_csv(my_table_g)

ggplot(all) +
  geom_bar(
    mapping = aes(x = foot_syls, fill = nuc_contour),
    colour = "black",
    show.legend = FALSE,
    position = position_dodge2(preserve = "single")
  ) +
  facet_grid(rows = vars(gender), cols = vars(nuc_contour)) +
  ggtitle("Nuclear Contours by Gender and Foot Size (adjusted") +
  scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
  labs(x = "foot size and gender",
       y = "tokens (n)") +
  theme(panel.border = element_rect(fill = NA))


ggplot(all) +
  geom_bar(
    mapping = aes(x = foot_syls, fill = nuc_contour),
    show.legend = FALSE,
    colour = "black",
    position = position_dodge2(preserve = "single")
  ) +
  facet_grid(cols = vars(nuc_contour)) +
  theme(panel.border = element_rect(fill = NA)) +
  ggtitle(
    "Nuclear Contours by Foot Size (adjusted)"
    ) +
  scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
  labs(x = "foot size (syllables)", y = "tokens (n)") +
  theme(panel.border = element_rect(fill = NA))

unlink(c(my_table_m, my_table_f, my_table_g))
```

### Nuclear Contours and Preceding Syllables
```{r}
# create temp file addresses
my_table_m <- paste(getwd(), "/output/nuc_pre_adj_M.csv", sep = "")
my_table_f <- paste(getwd(), "/output/nuc_pre_adj_F.csv", sep = "")
my_table_g <-
  paste(getwd(), "/output/nuc_pre_adj_all_gender.csv", sep = "")


pivot_longer(balancedData(nuc_pre, pre_syls, nuc_contour, "M", 5, 5),
             c(2:2),
             names_to = "nuc_contour") %>%
  write_csv(my_table_m)

pivot_longer(balancedData(nuc_pre, pre_syls, nuc_contour, "F", 6, 5),
             c(2:3),
             names_to = "nuc_contour") %>%
  write_csv(my_table_f)

# run Praat script for generating representative fake balanced data.
# (This was faster than doing it in R for me!)
script <- "../PraatScripts/adjustedSummaryByGender.praat"
my_treatment <- "pre_syls"
my_response <- "nuc_contour"
my_count <- "value"

praat_run(script,
          my_treatment,
          my_response,
          my_count,
          my_table_m,
          my_table_f,
          my_table_g)

all <- read_csv(my_table_g)

ggplot(all) +
  geom_bar(
    mapping = aes(x = pre_syls, fill = nuc_contour),
    colour = "black",
    show.legend = FALSE,
    position = position_dodge2(preserve = "single")
  ) +
  facet_grid(rows = vars(gender), cols = vars(nuc_contour)) +
  ggtitle("Nuclear Contours by Gender and preceding syllables (adjusted)") +
  scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
  labs(x = "foot size and gender",
       y = "tokens (n)") +
  theme(panel.border = element_rect(fill = NA))


ggplot(all) +
  geom_bar(
    mapping = aes(x = pre_syls, fill = nuc_contour),
    show.legend = FALSE,
    colour = "black",
    position = position_dodge2(preserve = "single")
  ) +
  facet_grid(cols = vars(nuc_contour)) +
  theme(panel.border = element_rect(fill = NA)) +
  ggtitle("Nuclear Contours by preceding syllables (adjusted)") +
  scale_fill_brewer(palette = "Spectral", name = "Pitch Accent") +
  labs(x = "foot size (syllables)", y = "tokens (n)") +
  theme(panel.border = element_rect(fill = NA))

unlink(c(my_table_m, my_table_f, my_table_g))
```

# **__1.4 Initial boundary and downstep__**
### foot size
```{r}
# create temp file addresses
my_table_m <- paste(getwd(), "/output/M.csv", sep = "")
my_table_f <- paste(getwd(), "/output/F.csv", sep = "")
my_table_g <- paste(getwd(), "/output/G.csv", sep = "")

pn_downstep %>%
  filter(stim %in% c("A0131", "A0221", "A0321", "A0423")) %>%
  balancedData(foot_syls, init_contour, "M", 5, 5, FALSE) %>%
  pivot_longer(c(2:7),
               names_to = "init_contour") %>%
  write_csv(my_table_m)


pn_downstep %>%
  filter(stim %in% c("A0131", "A0221", "A0321", "A0423")) %>%
  balancedData(foot_syls, init_contour, "F", 5, 6, FALSE) %>%
  pivot_longer(c(2:12),
               names_to = "init_contour") %>%
  write_csv(my_table_f)

# run Praat script for generating representative fake balanced data.
# (This was faster than doing it in R for me!)
script <- "../PraatScripts/adjustedSummaryByGender.praat"
my_treatment <- "foot_syls"
my_response <- "init_contour"
my_count <- "value"

praat_run(script,
          my_treatment,
          my_response,
          my_count,
          my_table_m,
          my_table_f,
          my_table_g)

all <- read_csv(my_table_g)

ggplot(all) +
  geom_bar(
    mapping = aes(x = foot_syls, fill = init_contour),
    colour = "black",
    show.legend = FALSE,
    position = position_dodge2(preserve = "single")
  ) +
  facet_grid(rows = vars(gender), cols = vars(init_contour)) +
  ggtitle("PNs by gender and foot size (adjusted)") +
  scale_fill_brewer(palette = "Spectral", name = "Initial Contour") +
  labs(x = "footsize  and gender",
       y = "tokens (n)") +
  theme(panel.border = element_rect(fill = NA))


ggplot(all) +
  geom_bar(
    mapping = aes(x = foot_syls, fill = init_contour),
    show.legend = FALSE,
    colour = "black",
    position = position_dodge2(preserve = "single")
  ) +
  facet_grid(cols = vars(init_contour)) +
  theme(panel.border = element_rect(fill = NA)) +
  ggtitle("PNs by foot size conditions (adjusted)") +
  scale_fill_brewer(palette = "Spectral", name = "init_contour") +
  labs(x = "foot size (syllables)", y = "tokens (n)") +
  theme(panel.border = element_rect(fill = NA))

unlink(c(my_table_m, my_table_f, my_table_g))
```

### anacrusis
```{r}
# create temp file addresses
my_table_m <-
  paste(getwd(), "/output/pn_ana_adj_M_ds.csv", sep = "")
my_table_f <-
  paste(getwd(), "/output/pn_ana_adj_F_ds.csv", sep = "")
my_table_g <-
  paste(getwd(), "/output/pn_ana_adj_all_gender_ds.csv", sep = "")

pn_downstep %>%
  filter(stim %in% c("A0423", "A1422", "A2422", "A3422")) %>%
  balancedData(ana_syls, init_contour, "M", 5, 5, FALSE) %>%
  pivot_longer(c(2:7),
               names_to = "init_contour") %>%
  write_csv(my_table_m)


pn_downstep %>%
  filter(stim %in% c("A0423", "A1422", "A2422", "A3422")) %>%
  balancedData(ana_syls, init_contour, "F", 5, 6, FALSE) %>%
  pivot_longer(c(2:6),
               names_to = "init_contour") %>%
  write_csv(my_table_f)

# run Praat script for generating representative fake balanced data.
# (This was faster than doing it in R for me!)
script <- "../PraatScripts/adjustedSummaryByGender.praat"
my_treatment <- "ana_syls"
my_response <- "init_contour"
my_count <- "value"

praat_run(script,
          my_treatment,
          my_response,
          my_count,
          my_table_m,
          my_table_f,
          my_table_g)

all <- read_csv(my_table_g)

ggplot(all) +
  geom_bar(
    mapping = aes(x = ana_syls, fill = init_contour),
    colour = "black",
    show.legend = FALSE,
    position = position_dodge2(preserve = "single")
  ) +
  facet_grid(rows = vars(gender), cols = vars(init_contour)) +
  ggtitle("PNs by gender and anacrusis (adjusted )") +
  scale_fill_brewer(palette = "Spectral", name = "Initial Contour") +
  labs(x = "anacrusis and gender",
       y = "tokens (n)") +
  theme(panel.border = element_rect(fill = NA))


ggplot(all) +
  geom_bar(
    mapping = aes(x = ana_syls, fill = init_contour),
    show.legend = FALSE,
    colour = "black",
    position = position_dodge2(preserve = "single")
  ) +
  facet_grid(cols = vars(init_contour)) +
  theme(panel.border = element_rect(fill = NA)) +
  ggtitle("PNs by anacrusis (adjusted)") +
  scale_fill_brewer(palette = "Spectral", name = "init_contour") +
  labs(x = "anacrusis (syllables)", y = "tokens (n)") +
  theme(panel.border = element_rect(fill = NA))

unlink(c(my_table_m, my_table_f, my_table_g))
```


```{r}

# create temp file addresses
my_table_m <- paste(getwd(), "/M_ds.csv", sep = "")
my_table_f <- paste(getwd(), "/F_ds.csv", sep = "")
my_table_g <- paste(getwd(), "/allds.csv", sep = "")

pn_downstep %>%
  filter(stim %in% c("A0423", "A1422", "A2422", "A3422")) %>%
  select(speaker, init_contour) %>%
  group_by(speaker, init_contour) %>%
  summarise(accCount = n()) %>%
  spread(init_contour, accCount, is.on <- 0) %>%
  kable()


pn_downstep %>%
  filter(stim %in% c("A0423", "A1422", "A2422", "A3422")) %>%
  select(speaker, init_contour) %>%
  group_by(speaker, init_contour) %>%
  summarise(accCount = n()) %>%
  spread(init_contour, accCount, is.on <- 0) %>%
  kable()


```


# **1.5 __Individiual Results__**

```{r results = "asis"}
# get vector of speakers
speaker_list <- unique(pn_foot$speaker)

# loop through speaker data
for (cur_speaker in speaker_list)
{
  cat(c("##", cur_speaker))
  cat(c("\n### Pre-nuclear contours"))
  
  # isolate current speaker in PN foot data
  pn_foot %>%
    filter (speaker == cur_speaker, .preserve = TRUE) %>%
    group_by(foot_syls, acc_phon) %>%
    summarise(accCount = n()) %>%
    spread(acc_phon, accCount, is.na <- 0, drop = FALSE) %>%
    kable(caption = c(cur_speaker, "PN foot size effects on PA")) %>%
    print()
  
  # isolate current speaker in PN anacrusis data
  pn_ana %>%
    filter (speaker == cur_speaker, .preserve = TRUE) %>%
    group_by(ana_syls, acc_phon) %>%
    summarise(accCount = n()) %>%
    spread(acc_phon, accCount, is.na <- 0, drop = FALSE) %>%
    kable(caption = c(cur_speaker, "PN anacrusis effects on PA")) %>%
    print()
  
  cat(c("\n### Nuclear contours"))
  
  # isolate current speaker in NUC foot data
  nuc_foot %>%
    filter (speaker == cur_speaker, .preserve = TRUE) %>%
    group_by(foot_syls, nuc_contour) %>%
    # repeated to avoid inconsistency in "drop = FALSE"
    mutate(nuc_contour = factor(nuc_contour, levels = c("L*H %", "L*H L%"))) %>%
    summarise(accCount = n()) %>%
    spread(nuc_contour, accCount, is.na <- 0, drop = FALSE) %>%
    kable(caption = c(cur_speaker, "NUC foot size effects on PA")) %>%
    print()
  
  # isolate current speaker in preceding syllables NUC data
  nuc_pre %>%
    filter (speaker == cur_speaker, .preserve = TRUE) %>%
    group_by(pre_syls, nuc_contour) %>%
    # repeated to avoid inconsistency in "drop = FALSE"
    mutate(nuc_contour = factor(nuc_contour, levels = c("L*H %", "L*H L%"))) %>%
    summarise(accCount = n()) %>%
    spread(nuc_contour, accCount, is.na <- 0, drop = FALSE) %>%
    kable(caption = c(cur_speaker, "NUC preceding syllable effects on PA")) %>%
    print()
}

```


